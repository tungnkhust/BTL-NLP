DATA:
  LABEL:
    sentiment:
      negative: 0
      neutral: 1
      positive: 2
    topic:
      lecturer: 0
      program: 1
      facility: 2
      other: 3
  GENERAL:
    data_path: data/processed
    max_char_len: 20
    max_seq_len: 162
    thresh_count_word: 0
    char_vocab_path: data/vocab/char_vocab.txt
    vocab_path: data/vocab.txt
    test_name: test.csv
    train_name: train.csv
    val_name: val.csv

  LANGUAGE_MODEL_DATA:
    data_path: data/lm
    test_name: test_lm.txt
    train_name: train_lm.txt
    val_name: null
  RAW:
    data_path: data/raw
  NORMALIZE:
    lower: true
    cleaned_emoji: false

MODEL:
    # encoder
  att_method: general
  dropout: 0.4
  hidden_size: 128
  load_w2v: true
  n_rnn_layers: 3
  rnn_dropout: 0.3
  embed_size: 50
  padding_idx: 0
  MODEL_PATH:
    encoder_name: encoder.pth
    lm_dir: models/lm
    model_dir: models
    w2v_path: models/pre_trained
TRAIN:
  batch_size: 64
  checkpoint: true
  clipping_gradient: 5
  early_stop_max_epochs: 3
  learning_rate: 0.0001
  max_char_len: null
  max_seq_len: null
  n_retrain: 1
  num_epochs: 200
  show_step: true
  stop_thresh: 0.0001
